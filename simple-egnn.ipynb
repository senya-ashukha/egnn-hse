{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6a5090",
   "metadata": {},
   "source": [
    "# Simple Impementation of E(n) Equivariant Graph Neural Networks\n",
    "\n",
    "Original paper https://arxiv.org/pdf/2102.09844.pdf by Victor Garcia Satorras, Emiel Hoogeboom, Max Welling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bU4ixrOJCg1",
   "metadata": {
    "id": "4bU4ixrOJCg1"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb08a10",
   "metadata": {},
   "source": [
    "# Load QM9 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae30de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'simple-equivariant-gnn'...\n",
      "remote: Enumerating objects: 84, done.\u001b[K\n",
      "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
      "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
      "remote: Total 84 (delta 35), reused 31 (delta 5), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (84/84), 175.01 KiB | 1.58 MiB/s, done.\n",
      "Resolving deltas: 100% (35/35), done.\n",
      "/Users/ars/Downloads/simple-equivariant-gnn-main/simple-equivariant-gnn\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/senya-ashukha/simple-equivariant-gnn.git\n",
    "%cd simple-equivariant-gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859f981c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "859f981c",
    "outputId": "3b62e11b-79be-4cbd-f9ff-38ccc05d013b"
   },
   "outputs": [],
   "source": [
    "# QM9 is a dataset for Molecular Property Predictions http://quantum-machine.org/datasets/\n",
    "# We will predict Highest occupied molecular orbital energy \n",
    "# https://en.wikipedia.org/wiki/HOMO_and_LUMO\n",
    "# We use data loaders from the official repo\n",
    "\n",
    "from qm9.data_utils import get_data, BatchGraph\n",
    "train_loader, val_loader, test_loader, charge_scale = get_data(num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e20004",
   "metadata": {},
   "source": [
    "# Graph Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0acbcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In the batch: num_graphs 96 num_nodes 1759\n",
       "> .h \t\t a tensor of nodes representations \t\tshape 1759 x 15\n",
       "> .x \t\t a tensor of nodes positions  \t\t\tshape 1759 x 3\n",
       "> .edges \t a tensor of edges, a fully connected graph \tshape 31288 x 2\n",
       "> .batch  \t a tensor of graph_ids for each node \t\ttensor([ 0,  0,  0,  ..., 95, 95, 95])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = BatchGraph(iter(train_loader).next(), False, charge_scale)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c0726",
   "metadata": {},
   "source": [
    "# Define Equivariant Graph Convs  & GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e5e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sum(agg_size, source, idx, cuda):\n",
    "    \"\"\"\n",
    "        source is N x hid_dim [float]\n",
    "        idx    is N           [int]\n",
    "        \n",
    "        Sums the rows source[.] with the same idx[.];\n",
    "    \"\"\"\n",
    "    tmp = torch.zeros((agg_size, source.shape[1]))\n",
    "    tmp = tmp.cuda() if cuda else tmp\n",
    "    res = torch.index_add(tmp, 0, idx, source)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d5d55db",
   "metadata": {
    "id": "4d5d55db"
   },
   "outputs": [],
   "source": [
    "class ConvEGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, cuda=True):\n",
    "        super().__init__()\n",
    "        self.hid_dim=hid_dim\n",
    "        self.cuda = cuda\n",
    "        \n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # computes messages based on hidden representations -> [0, 1]\n",
    "        self.f_e = # ....\n",
    "        # Tips: See eq. 3 from the paper.\n",
    "        # Also use nn.Sequential\n",
    "        \n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # preducts \"soft\" edges based on messages \n",
    "        self.f_inf = # ...\n",
    "        # Tips: See eq. 8 from the paper.\n",
    "        \n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # updates hidden representations -> [0, 1]\n",
    "        self.f_h = # ...\n",
    "        # Tips: See eq. 6 from the paper.\n",
    "    \n",
    "    def forward(self, b):\n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # compute distances for all edges\n",
    "        e_st, e_end = b.edges[:,0], b.edges[:,1]\n",
    "        dists = # ....\n",
    "        # dist should be a 2d torch.Tensor of shape (#number_of_edges_in_the_batch, 1)\n",
    "        \n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # compute messages\n",
    "        tmp = torch.hstack([b.h[e_st], b.h[e_end], dists])\n",
    "        m_ij = # ....\n",
    "        # m_ij should be a 2d torch.Tensor of shape (#number_of_edges_in_the_batch, hid_dim)\n",
    "        \n",
    "        # predict edges\n",
    "        e_ij = self.f_inf(m_ij)\n",
    "        \n",
    "        # average e_ij-weighted messages  \n",
    "        # m_i is num_nodes x hid_dim\n",
    "        m_i = index_sum(b.h.shape[0], e_ij*m_ij, b.edges[:,0], self.cuda)\n",
    "        \n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # update hidden representations\n",
    "        b.h = # ....\n",
    "        # b.h should be a 2d torch.Tensor of shape (#number_of_nodes_in_the_batch, hid_dim)\n",
    "        # see appendix C. Implementatation details\n",
    "\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10aad7c4",
   "metadata": {
    "id": "10aad7c4"
   },
   "outputs": [],
   "source": [
    "class NetEGNN(nn.Module):\n",
    "    def __init__(self, in_dim=15, hid_dim=128, out_dim=1, n_layers=7, cuda=True):\n",
    "        super().__init__()\n",
    "        self.hid_dim=hid_dim\n",
    "        \n",
    "        self.emb = nn.Linear(in_dim, hid_dim) \n",
    "\n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # Make gnn of n_layers\n",
    "        self.gnn = # .... \n",
    "        # use ConvEGNN layer\n",
    "        \n",
    "        self.pre_mlp = nn.Sequential(\n",
    "            nn.Linear(hid_dim, hid_dim), nn.SiLU(),\n",
    "            nn.Linear(hid_dim, hid_dim))\n",
    "        \n",
    "        self.post_mlp = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hid_dim, hid_dim), nn.SiLU(),\n",
    "            nn.Linear(hid_dim, out_dim))\n",
    "\n",
    "        if cuda: self.cuda()\n",
    "        self.cuda = cuda\n",
    "    \n",
    "    def forward(self, b):\n",
    "        b.h = self.emb(b.h)\n",
    "        \n",
    "        b = self.gnn(b)\n",
    "        h_nodes = self.pre_mlp(b.h)\n",
    "        \n",
    "        # h_graph is num_graphs x hid_dim\n",
    "        h_graph = index_sum(b.nG, h_nodes, b.batch, self.cuda) \n",
    "        \n",
    "        out = self.post_mlp(h_graph)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f4cef6",
   "metadata": {
    "id": "b7f4cef6"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "cuda = True\n",
    "\n",
    "model = NetEGNN(n_layers=7, cuda=cuda)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-16)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5d6b1c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3613c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de3613c9",
    "outputId": "a924add2-aadc-4669-e7cb-3a92c13ba5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> start training\n",
      "> epoch 000: "
     ]
    }
   ],
   "source": [
    "print('> start training')\n",
    "\n",
    "tr_ys = train_loader.dataset.data['homo'] \n",
    "me, mad = torch.mean(tr_ys), torch.mean(torch.abs(tr_ys - torch.mean(tr_ys)))\n",
    "\n",
    "if cuda:\n",
    "    me = me.cuda()\n",
    "    mad = mad.cuda()\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "test_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('> epoch %s:' % str(epoch).zfill(3), end=' ', flush=True) \n",
    "    start = time.time()\n",
    "\n",
    "    batch_train_loss = []\n",
    "    batch_val_loss = []\n",
    "    batch_test_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = BatchGraph(batch, cuda, charge_scale)\n",
    "        \n",
    "        out = model(batch).reshape(-1)\n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # compute l1-loss \n",
    "        loss =  # ...\n",
    "        # use (batch.y-me)/mad as the true value\n",
    "\n",
    "        loss.backward()\n",
    "        #### **** YOUR CODE HERE **** #####\n",
    "        # make step of opimizer \n",
    "        # google it\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss =  F.l1_loss(out*mad+me, batch.y)\n",
    "\n",
    "        batch_train_loss += [float(loss.data.cpu().numpy())]  \n",
    "        \n",
    "    train_loss += [np.mean(batch_train_loss)/0.001]\n",
    "    \n",
    "    print('train %.3f' % train_loss[-1], end=' ', flush=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            batch = BatchGraph(batch, cuda, charge_scale)\n",
    "            out = model(batch).reshape(-1)\n",
    "            loss = F.l1_loss(out*mad+me, batch.y).data.cpu().numpy()\n",
    "            batch_val_loss += [np.mean(loss)]\n",
    "            \n",
    "        val_loss += [np.mean(batch_val_loss)/0.001]\n",
    "        \n",
    "        print('val %.3f' % val_loss[-1], end=' ', flush=True)\n",
    "        \n",
    "        for batch in test_loader:\n",
    "            batch = BatchGraph(batch, cuda, charge_scale)\n",
    "            out = model(batch).reshape(-1)\n",
    "            loss = F.l1_loss(out*mad+me, batch.y).data.cpu().numpy()\n",
    "            batch_test_loss += [np.mean(loss)]\n",
    "\n",
    "        test_loss += [np.mean(batch_test_loss)/0.001]\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print('test %.3f (%.1f sec)' % (test_loss[-1], end-start), flush=True)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7825a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is good results \n",
    "# Lower is better\n",
    "# val 30.157 test 30.886"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph_seminar_homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
